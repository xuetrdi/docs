* 使用C API部署TensorFlow Saved Model 模型CPU版本
** 依赖环境
   - OS: Ubuntu 18.04
   - Compiler: Latest GCC
   - TensorFlow Source branch 2.1

** 使用源码构建C API库
   - 克隆拉取TensorFlow源码仓库并切换到r2.1分支
   - 安装构建工具Bazel
   - 安装TensorFlow依赖库Numpy
   - 编译代码
   #+BEGIN_SRC sh
     git clone https://github.com/tensorflow/tensorflow.git 
     cd tensorflow && git checkout r2.1
     pip install numpy
     bazel test -c opt tensorflow/tools/lib_package:libtensorflow_test
     bazel build -c opt tensorflow/tools/lib_package:libtensorflow_test
     cd bazel-bin/tensorflow/tools/lib_package
     tar -C /usr/local -xzf libtensorflow.tar.gz
   #+END_SRC

** 使用Python训练一个简单的模型生成Saved Model格式模型文件
   #+begin_src python
     import numpy as np
     import tensorflow as tf
     from tensorflow import keras
     from tensorflow.keras import layers

     class testModel(tf.keras.Model):
       def __init__(self):
         super(testModel, self).__init__()
         self.dense1 = tf.keras.layers.Dense(1, kernel_initializer='Ones', activation=tf.nn.relu)

       def call(self, inputs):
         return self.dense1(inputs)

     input_data = np.asarray([[10]])
     # 创建模型
     module = testModel()
     # 设置模型输入
     module._set_inputs(input_data)
     # 把输入数据送入模型运行一遍
     print(module(input_data))

     # Export the model to a SavedModel
     # 以tf格式保存模型即,以saved_model格式保存
     module.save('model', save_format='tf')
   #+end_src
   
   #+begin_src sh
     # 训练模型, 以上模型代码写入model.py
     python model.py 
   #+end_src

** 验证模型
   使用TensorFlow自带的Saved Model验证工具验证模型并查看模型的输入输出
   #+begin_src sh
     # 在训练模型的目录下会生成一个model的目录文件
     saved_model_cli show --dir ./model --tag_set serve --signature_def serving_default
   #+end_src
   会得到如下结果
   #+begin_example
     The given SavedModel SignatureDef contains the following input(s):
       inputs['input_1'] tensor_info:
           dtype: DT_INT64
           shape: (-1, 1)
           name: serving_default_input_1:0
     The given SavedModel SignatureDef contains the following output(s):
       outputs['output_1'] tensor_info:
           dtype: DT_FLOAT
           shape: (-1, 1)
           name: StatefulPartitionedCall:0
     Method name is: tensorflow/serving/predict
   #+end_example
   我们需要模型是输入和输出名字
   输入名字: serving_default_input_1
   输出名字: StatefulPartitionedCall
   
** 构建C代码
   #+begin_src C
#include <stdlib.h>
#include <stdio.h>
#include "tensorflow/c/c_api.h"

void NoOpDeallocator(void* data, size_t a, void* b) {}
int main()
{
	TF_Graph* Graph = TF_NewGraph();
  TF_Status* Status = TF_NewStatus();
  TF_SessionOptions* SessionOpts = TF_NewSessionOptions();
  TF_Buffer* RunOpts = NULL;

  const char* saved_model_dir = "model/";
  const char* tags = "serve";

  int ntags = 1;
  TF_Session* Session = TF_LoadSessionFromSavedModel(SessionOpts, RunOpts, saved_model_dir, &tags, ntags, Graph, NULL, Status);

  if(TF_GetCode(Status) == TF_OK)
  {
    printf("TF_LoadSessionFromSavedModel OK\n");
  }
  else
  {
    printf("%s",TF_Message(Status));
  }

	/* Get Input Tensor */
	int NumInputs = 1;
  TF_Output* Input = malloc(sizeof(TF_Output) * NumInputs);
  TF_Output t0 = {TF_GraphOperationByName(Graph, "serving_default_input_1"), 0};

  if(t0.oper == NULL)
    printf("ERROR: Failed TF_GraphOperationByName serving_default_input_1\n");
  else
    printf("TF_GraphOperationByName serving_default_input_1 is OK\n");

  Input[0] = t0;

  //********* Get Output tensor
  int NumOutputs = 1;
  TF_Output* Output = malloc(sizeof(TF_Output) * NumOutputs);
  TF_Output t2 = {TF_GraphOperationByName(Graph, "StatefulPartitionedCall"), 0};

  if(t2.oper == NULL)
      printf("ERROR: Failed TF_GraphOperationByName StatefulPartitionedCall\n");
  else
    printf("TF_GraphOperationByName StatefulPartitionedCall is OK\n");

  Output[0] = t2;

	/* Allocate data for inputs and outputs */
	TF_Tensor** InputValues  = (TF_Tensor**)malloc(sizeof(TF_Tensor*)*NumInputs);
  TF_Tensor** OutputValues = (TF_Tensor**)malloc(sizeof(TF_Tensor*)*NumOutputs);

  int ndims = 2;
  int64_t dims[] = {1,1};
  int64_t data[] = {20};

  int ndata = sizeof(int64_t);
  TF_Tensor* int_tensor = TF_NewTensor(TF_INT64, dims, ndims, data, ndata, &NoOpDeallocator, 0);

  if (int_tensor != NULL)
    printf("TF_NewTensor is OK\n");
  else
    printf("ERROR: Failed TF_NewTensor\n");

  InputValues[0] = int_tensor;


	// Run the Session
  TF_SessionRun(Session, NULL, Input, InputValues, NumInputs, Output, OutputValues, NumOutputs, NULL, 0,NULL , Status);

  if(TF_GetCode(Status) == TF_OK)
    printf("Session is OK\n");
  else
    printf("%s",TF_Message(Status));

  // Free memory
  TF_DeleteGraph(Graph);
  TF_DeleteSession(Session, Status);
  TF_DeleteSessionOptions(SessionOpts);
  TF_DeleteStatus(Status);


	/* Get Output Result */
	void* buff = TF_TensorData(OutputValues[0]);
  float* offsets = buff;
  printf("Result Tensor :\n");
  printf("%f\n",offsets[0]);  // TF_GraphGetTensorNumDims 这里我们知道只有一维,负责可以使用这个函数获取维度
  return 0;
} 
   #+end_src
   将以上代码写入到predict.c文件中
   这里要注意，因为我们知道模型结果是一维的，直接取结果offsets的第一个，如果有多维的话，可以用过注释里面操作
   
** 编译C代码
   #+begin_src sh
     gcc -I/usr/local/include -L/usr/local/lib predict.c -ltensorflow -o predict
   #+end_src
** 配置环境变量
   运行之前需要配置环境变量，把TensorFlow的动态库路径配置到系统动态库路径中
   #+begin_src sh
     export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib 
   #+end_src
** 运行C程序
   #+begin_src sh
     ./predict
   #+end_src
   结果如下
   #+begin_example
     TF_LoadSessionFromSavedModel OK
     TF_GraphOperationByName serving_default_input_1 is OK
     TF_GraphOperationByName StatefulPartitionedCall is OK
     TF_NewTensor is OK
     Session is OK
     Result Tensor :
     20.000000
   #+end_example
